{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771dc111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27080\\3085240574.py:8: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv(file_path)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27080\\3085240574.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature] = label_encoders[feature].fit_transform(X[feature])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = (\"C:\\\\Users\\\\admin\\\\Downloads\\\\updated_dataset_with_water_well_suitability.csv\")\n",
    "data=pd.read_csv(file_path)\n",
    "# Function to determine water well suitability\n",
    "def determine_suitability(row):\n",
    "    if row['AQUIFER_TYPE'] == 'Unconfined' and row['WLS_WTR_LEVEL_Categorized'] == 'Shallow':\n",
    "        return 'Highly Suitable'\n",
    "    elif row['Broad_Soil_Type'] in ['Loamy', 'Sandy'] and row['WLS_WTR_LEVEL_Categorized'] in ['Shallow', 'Artesian']:\n",
    "        return 'Highly Suitable'\n",
    "    elif row['SITE_TYPE'] == 'Dug Well':\n",
    "        return 'Highly Suitable'\n",
    "    elif row['AQUIFER_TYPE'] == 'Semi-Confined' and row['WLS_WTR_LEVEL_Categorized'] in ['Shallow', 'Artesian']:\n",
    "        return 'Moderately Suitable'\n",
    "    elif row['Broad_Soil_Type'] in ['Rocky/Gravelly', 'Others'] and row['WLS_WTR_LEVEL_Categorized'] in ['Shallow', 'Artesian']:\n",
    "        return 'Moderately Suitable'\n",
    "    elif row['SITE_TYPE'] == 'Tube Well':\n",
    "        return 'Moderately Suitable'\n",
    "    else:\n",
    "        return 'Not Suitable'\n",
    "\n",
    "# Apply the function to create the new suitability label\n",
    "data['Water_Well_Suitability'] = data.apply(determine_suitability, axis=1)\n",
    "\n",
    "# Selecting features and target variable\n",
    "features = ['AQUIFER_TYPE', 'Broad_Soil_Type', 'WLS_WTR_LEVEL_Categorized', 'SITE_TYPE']\n",
    "X = data[features]\n",
    "y = data['Water_Well_Suitability']\n",
    "\n",
    "# Encoding categorical features\n",
    "label_encoders = {}\n",
    "for feature in features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    X[feature] = label_encoders[feature].fit_transform(X[feature])\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# The model is now trained and can be used for predictions or further analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed34995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\GWL\\\\src\\\\water_qality\\\\path_to_save_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# MODEL1\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from flask_cors import CORS  # Import CORS\n",
    "import logging\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the model\n",
    "# model_save_path = 'E:\\\\GWL\\\\src\\\\water_qality\\\\path_to_save_model.pkl'\n",
    "# joblib.dump(rf_classifier, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65ae2d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdatASET\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsefulldata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnw\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdepth.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mjoblib\u001b[49m\u001b[38;5;241m.\u001b[39mload(model_save_path)\n\u001b[0;32m      3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "model=\"E:\\\\datASET\\\\Usefulldata\\\\nw\\\\depth.pkl\"\n",
    "model=joblib.load(model_save_path)\n",
    "data['Latitude'] = pd.to_numeric(data['Latitude'], errors='coerce')\n",
    "data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')\n",
    "data.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
    "\n",
    "coordinates1 = data[['Latitude', 'Longitude']].values\n",
    "neigh2 = NearestNeighbors(n_neighbors=1)\n",
    "neigh2.fit(coordinates1)\n",
    "\n",
    "lat=37.496176495518768\n",
    "lng=88.7773061532471\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "distances, indices = neigh2.kneighbors(np.array([[lat, lng]]))\n",
    "nearest_index = indices[0][0]\n",
    "result = data.iloc[[nearest_index]]\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4525e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SimpleImputer from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SimpleImputer from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SimpleImputer from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ColumnTransformer from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude__well</th>\n",
       "      <th>Longitude__well</th>\n",
       "      <th>SITE_TYPE</th>\n",
       "      <th>SITE_SUB_TYPE</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>AQUIFER_TYPE</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>WLS_DATE</th>\n",
       "      <th>WLS_WTR_LEVEL</th>\n",
       "      <th>WLS_DRY_WELL</th>\n",
       "      <th>...</th>\n",
       "      <th>Annual Extractable Ground Water Resource</th>\n",
       "      <th>Current Annual Ground Water Extraction For Irrigation</th>\n",
       "      <th>Current Annual Ground Water Extraction For Domestic &amp; Industrial Use</th>\n",
       "      <th>Total Current Annual Ground Water Extraction</th>\n",
       "      <th>Annual GW Allocation for Domestic Use as on 2025</th>\n",
       "      <th>Net Ground Water Availability for future use</th>\n",
       "      <th>Stage of Ground Water Extraction (%)</th>\n",
       "      <th>dist_rainfall</th>\n",
       "      <th>Lithology_Type_Full</th>\n",
       "      <th>Soil_Type_Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35415</th>\n",
       "      <td>29.330556</td>\n",
       "      <td>74.980556</td>\n",
       "      <td>Dug Well</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jamal</td>\n",
       "      <td>Unconfined</td>\n",
       "      <td>31</td>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>4.18</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>65223.7</td>\n",
       "      <td>128027.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>128883.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>0.272873</td>\n",
       "      <td>Quaternary sediments</td>\n",
       "      <td>Haplic Yermosols</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude__well  Longitude__well SITE_TYPE SITE_SUB_TYPE SITE_NAME  \\\n",
       "35415       29.330556        74.980556  Dug Well           NaN     Jamal   \n",
       "\n",
       "      AQUIFER_TYPE DEPTH    WLS_DATE  WLS_WTR_LEVEL WLS_DRY_WELL  ...  \\\n",
       "35415   Unconfined    31  2022-01-30           4.18            N  ...   \n",
       "\n",
       "      Annual Extractable Ground Water Resource  \\\n",
       "35415                                  65223.7   \n",
       "\n",
       "       Current Annual Ground Water Extraction For Irrigation  \\\n",
       "35415                                           128027.0       \n",
       "\n",
       "      Current Annual Ground Water Extraction For Domestic & Industrial Use  \\\n",
       "35415                                              856.0                     \n",
       "\n",
       "      Total Current Annual Ground Water Extraction  \\\n",
       "35415                                     128883.0   \n",
       "\n",
       "       Annual GW Allocation for Domestic Use as on 2025  \\\n",
       "35415                                            1775.0   \n",
       "\n",
       "       Net Ground Water Availability for future use  \\\n",
       "35415                                           0.0   \n",
       "\n",
       "       Stage of Ground Water Extraction (%)  dist_rainfall  \\\n",
       "35415                                 197.6       0.272873   \n",
       "\n",
       "        Lithology_Type_Full    Soil_Type_Full  \n",
       "35415  Quaternary sediments  Haplic Yermosols  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"E:\\\\datASET\\\\Usefulldata\\\\nw\\\\depth.pkl\"\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "model=joblib.load(path)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Importing necessary libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# path=\"C:\\\\datASET\\\\Final\\\\updated_gdf_well_soil_lithology_rainfall_with_lithology.csv\"\n",
    "df2=pd.read_csv('E:\\\\datASET\\\\Usefulldata\\\\nw\\\\updated_gdf_well_soil_lithology_rainfall_with_lithology.csv')\n",
    "df.head()\n",
    "df2['Latitude'] = pd.to_numeric(df2['Latitude'], errors='coerce')\n",
    "df2['Longitude'] = pd.to_numeric(df2['Longitude'], errors='coerce')\n",
    "df2.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
    "df.head()\n",
    "coordinates2 = df2[['Latitude', 'Longitude']].values\n",
    "neigh5 = NearestNeighbors(n_neighbors=1)\n",
    "neigh5.fit(coordinates2)\n",
    "lat=29.430789480840957\n",
    "lng=74.99153373951383\n",
    "distances, indices = neigh5.kneighbors(np.array([[lat, lng]]))\n",
    "nearest_index = indices[0][0]\n",
    "result_2=df.iloc[[nearest_index]]\n",
    "result_2\n",
    "columns_to_drop = ['Unnamed: 0', 'SITE_ID', 'STATE_NAME', 'DISTRICT_NAME', 'TAHSIL_NAME', 'BLOCK_NAME', 'Longitude__rainfall', 'Latitude__rainfall']\n",
    "relevant_df = result.drop(columns=columns_to_drop)\n",
    "relevant_df\n",
    "# Separating the target variable and features\n",
    "# X = result_2.drop('WLS_WTR_LEVEL', axis=1)\n",
    "# y = df['WLS_WTR_LEVEL']\n",
    "# prediction=model.predict(X)\n",
    "# prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
